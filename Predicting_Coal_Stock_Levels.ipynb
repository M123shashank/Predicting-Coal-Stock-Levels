{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1yZr5RhD02ITuv00YScybF9aC3C9FiZID",
      "authorship_tag": "ABX9TyPzNziXjRodI9BriYHz52ey",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M123shashank/Predicting-Coal-Stock-Levels/blob/main/Predicting_Coal_Stock_Levels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.base import clone\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, r2_score, accuracy_score, precision_score, recall_score\n",
        "\n",
        "# 1. Load daily data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Datasets/daily-coal-stocks.csv\", dtype={'utility': 'str'},\n",
        "                 parse_dates=[\"date\"])\n",
        "\n",
        "# 2. Data Cleaning\n",
        "# Fill 'unknown' in place of None in 'utility'\n",
        "df['utility'] = df['utility'].fillna('unknown')\n",
        "\n",
        "# Remove rows with missing capacity_in_mw\n",
        "missing_capacity_rows = df[df['capacity_in_mw'].isna()]\n",
        "df.dropna(subset=['capacity_in_mw'], inplace=True)\n",
        "\n",
        "# Fill missing 'req_for_day_in_th_tonnes' using normative stock / stock days if required features not missing\n",
        "df = df.dropna(subset=['req_for_day_in_th_tonnes', 'normative_stock_req_in_th_tonnes'], how='all')\n",
        "mask_4 = df['req_for_day_in_th_tonnes'].isna() & df['normative_stock_req_in_th_tonnes'].notna() & df['normative_stock_req_days'].notna()\n",
        "df.loc[mask_4, 'req_for_day_in_th_tonnes'] = (df.loc[mask_4, 'normative_stock_req_in_th_tonnes'] / df.loc[mask_4, 'normative_stock_req_days']\n",
        ")\n",
        "\n",
        "# Drop rows where 'normative_stock_req_days' is missing and neither normative stock nor percentage is available\n",
        "mask_5 = (df['normative_stock_req_days'].isna() & df['normative_stock_req_in_th_tonnes'].isna() &\n",
        "          df['percentage_of_actual_stock_vs_normative_stock'].isna())\n",
        "df = df[~mask_5]\n",
        "\n",
        "# Fill normative stock where daily req and days are known\n",
        "mask_6 = df['normative_stock_req_in_th_tonnes'].isna() & df['req_for_day_in_th_tonnes'].notna() & df['normative_stock_req_days'].notna()\n",
        "df.loc[mask_6, 'normative_stock_req_in_th_tonnes'] = (\n",
        "    df.loc[mask_6, 'req_for_day_in_th_tonnes'] * df.loc[mask_6, 'normative_stock_req_days'])\n",
        "\n",
        "# Calculate actual stock days as well as percentage_of_actual_stock_vs_normative_stock\n",
        "mask_8 = df['actual_stock_total_in_th_tonnes'].notna() & df['req_for_day_in_th_tonnes'].notna()\n",
        "df.loc[mask_8, 'actual_stock_days'] = (\n",
        "    df.loc[mask_8, 'actual_stock_total_in_th_tonnes'] / df.loc[mask_8, 'req_for_day_in_th_tonnes'])\n",
        "\n",
        "mask_9 = df['actual_stock_total_in_th_tonnes'].notna() & df['normative_stock_req_in_th_tonnes'].notna()\n",
        "df.loc[mask_9, 'percentage_of_actual_stock_vs_normative_stock'] = (\n",
        "    100 * df.loc[mask_9, 'actual_stock_total_in_th_tonnes'] / df.loc[mask_9, 'normative_stock_req_in_th_tonnes'])\n",
        "\n",
        "# Drop the last two columns, which are of no use and do some basic preprocessing\n",
        "df = df.drop(columns=['critical_or_sup_critical','reasons_for_critical_remarks'], errors='ignore')\n",
        "df['year'] = df['date'].dt.year\n",
        "df['month'] = df['date'].dt.month\n",
        "\n",
        "# Clean transport modes\n",
        "df['mode_of_transport'] = df['mode_of_transport'].str.strip().replace({\n",
        "    'Raiil': 'Rail', 'Rail-Sea': 'Sea', 'Rail-Sea-1500': 'Sea',\n",
        "    'Rail-Sea ': 'Sea', 'Rail-Sea-Rail': 'Sea', 'Rail-1500': 'Rail'})\n",
        "\n",
        "# 3. Aggregate to monthly level\n",
        "monthly = df.groupby(['year','month']).agg(\n",
        "    avg_stock=('actual_stock_total_in_th_tonnes','mean'),\n",
        "    std_stock=('actual_stock_total_in_th_tonnes','std'),\n",
        "    total_stock=('actual_stock_total_in_th_tonnes','sum'),\n",
        "    count_plants=('power_station_name','nunique')\n",
        ").reset_index()\n",
        "\n",
        "# Do Sector-level & Transport-mode totals and merge with monthly\n",
        "sector_totals = df.groupby(['year','month','sector'])['actual_stock_total_in_th_tonnes'] \\\n",
        "                  .sum().unstack(fill_value=0).reset_index()\n",
        "mode_totals = df.groupby(['year','month','mode_of_transport'])['actual_stock_total_in_th_tonnes'] \\\n",
        "                .sum().unstack(fill_value=0).reset_index()\n",
        "\n",
        "monthly = monthly.merge(sector_totals, on=['year','month'], how='left') \\\n",
        "                 .merge(mode_totals, on=['year','month'], how='left').fillna(0)\n",
        "\n",
        "# Create fractional features\n",
        "monthly['frac_central']    = monthly.get('Central Sector', 0) / monthly['total_stock']\n",
        "monthly['frac_state']      = monthly.get('State Sector', 0) / monthly['total_stock']\n",
        "monthly['frac_pvt']        = monthly.get('Pvt Sector', 0) / monthly['total_stock']\n",
        "monthly['frac_joint']      = monthly.get('Joint Venture', 0) / monthly['total_stock']\n",
        "monthly['frac_rail']       = monthly.get('Rail', 0) / monthly['total_stock']\n",
        "monthly['frac_road']       = monthly.get('Road', 0) / monthly['total_stock']\n",
        "monthly['frac_sea']        = monthly.get('Sea', 0) / monthly['total_stock']\n",
        "monthly['frac_pithead']    = monthly.get('Pithead', 0) / monthly['total_stock']\n",
        "monthly['frac_intermodal'] = monthly.get('Inter Modal', 0) / monthly['total_stock']\n",
        "\n",
        "# Month cyclic encoding\n",
        "monthly['month_sin'] = np.sin(2 * np.pi * monthly['month'] / 12)\n",
        "monthly['month_cos'] = np.cos(2 * np.pi * monthly['month'] / 12)\n",
        "\n",
        "# 4. Add target: next year's stock and binary label\n",
        "def get_next_year_stock(row):\n",
        "    mask = (monthly['year'] == row['year'] + 1) & (monthly['month'] == row['month'])\n",
        "    next_val = monthly[mask]['avg_stock']\n",
        "    return next_val.values[0] if not next_val.empty else np.nan\n",
        "\n",
        "monthly.loc[:,'next_year_stock'] = monthly.apply(get_next_year_stock, axis=1)\n",
        "monthly = monthly.dropna(subset=['next_year_stock'])\n",
        "calculated_label = (monthly['next_year_stock'] >= 1.1 * monthly['avg_stock']).astype(int)\n",
        "monthly.loc[:, 'label'] = calculated_label\n",
        "\n",
        "# 5. Feature matrix\n",
        "features = ['avg_stock', 'std_stock', 'count_plants',\n",
        "            'frac_central', 'frac_state', 'frac_pvt', 'frac_joint',\n",
        "            'frac_rail', 'frac_road', 'frac_sea', 'frac_pithead', 'frac_intermodal',\n",
        "            'month_sin', 'month_cos']\n",
        "X = monthly[features]\n",
        "y_cls = monthly['label']\n",
        "y_reg = monthly['next_year_stock']\n",
        "\n",
        "# 6. Train/test split\n",
        "X_train, X_test, y_train_cls, y_test_cls, y_train_reg, y_test_reg = train_test_split(\n",
        "    X, y_cls, y_reg, test_size=0.2, random_state=42, stratify=y_cls)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled  = scaler.transform(X_test)\n",
        "\n",
        "# 7. Base regressors\n",
        "base_models = [\n",
        "    ('Linear', LinearRegression()),\n",
        "    ('XGB',    XGBRegressor(n_estimators=100, random_state=42, objective='reg:squarederror')),\n",
        "    ('SVM', SVR(kernel = 'poly', C=1000.0)),\n",
        "    ('NN',     MLPRegressor(hidden_layer_sizes=(500,), activation='logistic', solver='lbfgs', max_iter=8000, random_state=0))\n",
        "]\n",
        "\n",
        "# Cross-validated out-of-fold predictions\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "oof_preds = np.zeros((X_train.shape[0], len(base_models)))\n",
        "test_preds = np.zeros((X_test.shape[0], len(base_models)))\n",
        "\n",
        "for i, (name, model) in enumerate(base_models):\n",
        "    oof = np.zeros(X_train.shape[0])\n",
        "    for train_idx, valid_idx in skf.split(X_train_scaled, y_train_cls):\n",
        "        model_clone = clone(model)\n",
        "        model_clone.fit(X_train_scaled[train_idx], y_train_reg.iloc[train_idx])\n",
        "        oof[valid_idx] = model_clone.predict(X_train_scaled[valid_idx])\n",
        "    oof_preds[:, i] = oof\n",
        "    # Final test predictions\n",
        "    model.fit(X_train_scaled, y_train_reg)\n",
        "    test_preds[:, i] = model.predict(X_test_scaled)\n",
        "\n",
        "# Train a meta-model on out-of-fold predictions for regression\n",
        "reg_meta_model = LinearRegression()\n",
        "reg_meta_model.fit(oof_preds, y_train_reg)\n",
        "\n",
        "# Predict on test data using stacked model\n",
        "final_reg_preds = reg_meta_model.predict(test_preds)\n",
        "\n",
        "# Evaluate\n",
        "print(f\"R² Score:             {r2_score(y_test_reg, final_reg_preds):.4f}\")\n",
        "print(f\"Mean Absolute Error:  {mean_absolute_error(y_test_reg, final_reg_preds):.4f}\")\n",
        "\n",
        "# 9. Classification with stacked predictions\n",
        "meta_model = LogisticRegression( class_weight='balanced', solver = 'liblinear', max_iter=1000, random_state=42)\n",
        "meta_model.fit(oof_preds, y_train_cls)\n",
        "final_cls_preds = meta_model.predict(test_preds)\n",
        "\n",
        "# 10. Classification evaluation\n",
        "print(\"\\nClassification Performance:\")\n",
        "print(\"Accuracy :\", accuracy_score(y_test_cls, final_cls_preds))\n",
        "print(\"Precision:\", precision_score(y_test_cls, final_cls_preds))\n",
        "print(\"Recall   :\", recall_score(y_test_cls, final_cls_preds))"
      ],
      "metadata": {
        "id": "Wlx0DJAYWn9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc5dfa4-6d24-4427-b42c-68567f2a7f7c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² Score:             0.7319\n",
            "Mean Absolute Error:  16.4640\n",
            "\n",
            "Classification Performance:\n",
            "Accuracy : 0.8\n",
            "Precision: 0.8333333333333334\n",
            "Recall   : 0.8333333333333334\n"
          ]
        }
      ]
    }
  ]
}